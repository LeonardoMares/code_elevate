 - Projeto: Monitoramento de Sensores IoT<br><br><br>
 
    - Vis√£o Geral<br>
    Este projeto implementa uma pipeline de dados em tempo real para simular, consumir e armazenar informa√ß√µes de sensores IoT utilizando:<br>
    
    Apache Kafka para mensageria<br>
    
    PostgreSQL para persist√™ncia dos dados<br>
    
    Docker Compose para orquestra√ß√£o dos servi√ßos<br>
    
    Python com bibliotecas espec√≠ficas para simula√ß√£o e integra√ß√£o<br><br><br>
    
    - Objetivo<br>
    Criar um ambiente completo para simula√ß√£o de sensores IoT<br>
    
    Enviar e processar mensagens em tempo real via Kafka<br>
    
    Armazenar os dados em um banco relacional (PostgreSQL)<br>
    
    Manter o projeto organizado, modular e test√°vel<br>
    
    Demonstrar conhecimento pr√°tico em streaming de dados, containeriza√ß√£o e persist√™ncia de dados<br><br><br>
    
    - Tecnologias Utilizadas<br>
    Apache Kafka: mensageria em tempo real (t√≥pico sensores-iot)<br>
    
    Zookeeper: coordena√ß√£o dos brokers Kafka<br>
    
    PostgreSQL: persist√™ncia dos dados (tabela monitoramento_sensores_iot)<br>
    
    Docker Compose: orquestra√ß√£o dos servi√ßos<br>
    
    Python 3.8+ com as bibliotecas:<br>
    
    kafka-python: conex√£o com Kafka<br>
    
    psycopg2: integra√ß√£o com PostgreSQL<br>
    
    Faker: gera√ß√£o de dados fict√≠cios<br>
    
    dotenv: leitura de vari√°veis de ambiente<br><br><br>

    - Pipeline de Execu√ß√£o<br>
    1. Inicie os containers Docker:
       docker-compose up -d<br>
    2. Instale as depend√™ncias Python:
       pip install -r requirements.txt<br>
    3. Crie um topico:
       docker exec -it kafka bash -c "kafka-topics.sh --create --topic meu_topico --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1" <br>
    4. Execute o Producer (gera e envia mensagens Kafka):
       python producer.py<br>
    5. Execute o Consumer (l√™ e armazena no PostgreSQL):
       python consumer.py<br>
    6. (Opcional): Rode consultas nos dados:
        python consulta_dados_sensor.py<br><br><br>

    - Configura√ß√£o do Ambiente
    Crie um arquivo .env na raiz do projeto com o seguinte conte√∫do:<br>

    POSTGRES_USER=sensores_user
    POSTGRES_PASSWORD=docker
    POSTGRES_DB=sensores_db
    (Esse arquivo ser√° lido automaticamente para configurar a conex√£o com o banco de dados, ele deveser usado dentro do arquivo .gitignore, para que seuas dados fique protegidos)<br><br><br>

    - Testes
    Os testes est√£o organizados no notebook testes.ipynb, incluindo:<br>
    
    Valida√ß√£o do schema das mensagens Kafka<br>
    
    Verifica√ß√£o de conex√£o com Kafka e PostgreSQL<br>
    
    Teste de persist√™ncia dos dados simulados<br><br><br>

    Para executar:<br>
   jupyter notebook testes.ipynb<br><br><br>

    - Melhorias Futuras<br>
    Funcionalidade    /     Descri√ß√£o<br>
    Autentica√ß√£o SASL/SSL    /    Adicionar seguran√ßa no broker Kafka<br>
    Particionamento de t√≥pico    /    Melhorar performance e escalabilidade<br>
    Dashboard    /    Visualiza√ß√£o via PowerBI<br>
    Alertas    /    Gera√ß√£o de alertas para anomalias dos sensores<br><br><br>

    üìå Considera√ß√µes Finais<br>
    Este projeto foi desenvolvido com foco em simular um cen√°rio real de IoT + streaming de dados, aplicando conceitos modernos de engenharia de dados em ambientes distribu√≠dos. Ele serve como uma base para evolu√ß√£o futura com ferramentas de monitoramento, analytics e seguran√ßa de dados.
    







    

    
